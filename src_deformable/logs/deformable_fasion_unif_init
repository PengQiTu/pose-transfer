nohup: ignoring input
Model options . .
  annotations_file_test: ../../pose-gan-clean/pose-gan/data/fasion-annotation-test.csv
  annotations_file_test_paf: ../../pose-gan-clean/pose-gan/data/fasion-annotation-paf-test0.csv
  annotations_file_train: ../../pose-gan-clean/pose-gan/data/fasion-annotation-train.csv
  annotations_file_train_paf: ../../pose-gan-clean/pose-gan/data/fasion-annotation-paf-train0.csv
  batch_size: 2
  checkpoint_ratio: 5
  checkpoints_dir: ../exp/deformable_fasion_unif_init/models
  compute_h36m_paf_split: 0
  content_loss_layer: none
  data_Dir: ../../pose-gan-clean/pose-gan/data/
  dataset: fasion
  disc_type: call
  discriminator_checkpoint: None
  display_ratio: 50
  expID: deformable_fasion_unif_init
  frame_diff: 10
  gan_penalty_weight: 1
  gen_type: baseline
  generated_images_dir: output/generated_images/fasion-restricted
  generator_checkpoint: None
  image_size: (256, 256)
  images_dir_test: ../../pose-gan-clean/pose-gan/data/fasion-dataset/test
  images_dir_train: ../../pose-gan-clean/pose-gan/data/fasion-dataset/train
  images_for_test: 12000
  iters_per_epoch: 1000
  l1_penalty_weight: 10.0
  learning_rate: 0.0002
  load_generated_images: 0
  log_file: output/full/fasion/log
  lstruct_penalty_weight: 0
  nn_loss_area_size: 1
  num_stacks: 4
  number_of_epochs: 90
  output_dir: ../exp/deformable_fasion_unif_init/results
  pairs_file_test: ../../pose-gan-clean/pose-gan/data/fasion-pairs-test.csv
  pairs_file_test_interpol: ../../pose-gan-clean/pose-gan/data/fasion-pairs-test-interpol.csv
  pairs_file_test_iterative: ../../pose-gan-clean/pose-gan/data/fasion-pairs-test-iterative.csv
  pairs_file_train: ../../pose-gan-clean/pose-gan/data/fasion-pairs-train.csv
  pairs_file_train_interpol: ../../pose-gan-clean/pose-gan/data/fasion-pairs-train-interpol.csv
  pairs_file_train_iterative: ../../pose-gan-clean/pose-gan/data/fasion-pairs-train-iterative.csv
  pose_dim: 18
  pose_estimator: pose_estimator.h5
  resume: 0
  saveDir: ../exp/deformable_fasion_unif_init
  start_epoch: 0
  tmp_pose_dir: tmp/fasion/
  training_ratio: 1
  tv_penalty_weight: 0
  use_dropout_test: 0
  use_input_pose: True
  warp_agg: max
  warp_skip: mask
(256, 256)
Statistics for loaded dataset : Human 3.6
Number of images: 52712
Number of pairs train: 101268
Number of pairs test: 8670
Statistics for loaded dataset : Human 3.6
Number of images: 52712
Number of pairs train: 101268
Number of pairs test: 8670
---------- Networks initialized -------------
Deformable_Generator(
  (encoder_app): encoder(
    (net): ModuleList(
      (0): Conv2d(21, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (2): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (3): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (4): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (5): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (6): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        )
      )
    )
  )
  (encoder_pose): encoder(
    (net): ModuleList(
      (0): Conv2d(18, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (2): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (3): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (4): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (5): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
          (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (6): Block(
        (net): Sequential(
          (0): LeakyReLU(negative_slope=0.2)
          (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        )
      )
    )
  )
  (decoder): decoder(
    (net): ModuleList(
      (0): Block(
        (net): Sequential(
          (0): ReLU()
          (1): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), bias=False)
          (2): Cropping2D()
          (3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (4): Dropout2d(p=0.5)
        )
      )
      (1): Block(
        (net): Sequential(
          (0): ReLU()
          (1): ConvTranspose2d(1536, 512, kernel_size=(4, 4), stride=(2, 2), bias=False)
          (2): Cropping2D()
          (3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (4): Dropout2d(p=0.5)
        )
      )
      (2): Block(
        (net): Sequential(
          (0): ReLU()
          (1): ConvTranspose2d(1536, 512, kernel_size=(4, 4), stride=(2, 2), bias=False)
          (2): Cropping2D()
          (3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          (4): Dropout2d(p=0.5)
        )
      )
      (3): Block(
        (net): Sequential(
          (0): ReLU()
          (1): ConvTranspose2d(1536, 512, kernel_size=(4, 4), stride=(2, 2), bias=False)
          (2): Cropping2D()
          (3): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (4): Block(
        (net): Sequential(
          (0): ReLU()
          (1): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), bias=False)
          (2): Cropping2D()
          (3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (5): Block(
        (net): Sequential(
          (0): ReLU()
          (1): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), bias=False)
          (2): Cropping2D()
          (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (6): ReLU()
      (7): Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): Tanh()
    )
  )
)/home/project/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/home/project/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)

Total number of parameters: 82080579
Discriminator(
  (net): Sequential(
    (0): Conv2d(42, 64, kernel_size=(4, 4), stride=(2, 2))
    (1): Block(
      (net): Sequential(
        (0): LeakyReLU(negative_slope=0.2)
        (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (2): Block(
      (net): Sequential(
        (0): LeakyReLU(negative_slope=0.2)
        (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (3): Block(
      (net): Sequential(
        (0): LeakyReLU(negative_slope=0.2)
        (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (4): Block(
      (net): Sequential(
        (0): LeakyReLU(negative_slope=0.2)
        (1): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
      )
    )
    (5): Sigmoid()
    (6): Flatten()
  )
)
Total number of parameters: 2803776
-----------------------------------------------
Traceback (most recent call last):
  File "main.py", line 132, in <module>
    main()
  File "main.py", line 72, in main
    model = DeformablePose_GAN(opt)
  File "/home/project/saurabh/pose-transfer/src_deformable/models/pose_gan.py", line 45, in __init__
    self.gen.cuda()
  File "/home/project/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 249, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/project/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 176, in _apply
    module._apply(fn)
  File "/home/project/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 176, in _apply
    module._apply(fn)
  File "/home/project/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 176, in _apply
    module._apply(fn)
  File "/home/project/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 182, in _apply
    param.data = fn(param.data)
  File "/home/project/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 249, in <lambda>
    return self._apply(lambda t: t.cuda(device))
  File "/home/project/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py", line 146, in _lazy_init
    def _lazy_init():
KeyboardInterrupt
